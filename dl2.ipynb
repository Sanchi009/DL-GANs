{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YfHUslvsX-jf"
      },
      "outputs": [],
      "source": [
        "# @title\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Dense, Input\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('data.csv')  # Replace 'your_dataset.csv' with your actual dataset file\n",
        "\n",
        "# Assuming 'Time' is the column containing the time values in \"mm:ss.s\" format\n",
        "df['Timestamp'] = pd.to_datetime(df['Date\\t'] + ' ' + df['Time'], format=\"%d-%m-%Y %M:%S.%f\")\n",
        "df.set_index('Timestamp', inplace=True)\n",
        "df.drop(['Date\\t', 'Time'], axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6_km2rm4X-jt"
      },
      "outputs": [],
      "source": [
        "# Normalize numerical features\n",
        "scaler = MinMaxScaler()\n",
        "df_normalized = pd.DataFrame(scaler.fit_transform(df), columns=df.columns)\n",
        "\n",
        "# Generator model\n",
        "generator = Sequential([\n",
        "    Dense(16, activation='relu', input_shape=(9,)),\n",
        "    Dense(9, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Discriminator model\n",
        "discriminator = Sequential([\n",
        "    Dense(16, activation='relu', input_shape=(9,)),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Combined model (GAN)\n",
        "discriminator.trainable = False\n",
        "gan_input = Input(shape=(9,))\n",
        "x = generator(gan_input)\n",
        "gan_output = discriminator(x)\n",
        "gan = Model(gan_input, gan_output)\n",
        "gan.compile(optimizer=Adam(learning_rate=0.0002, beta_1=0.5), loss='binary_crossentropy')\n",
        "\n",
        "# Compile discriminator\n",
        "discriminator.compile(optimizer=Adam(learning_rate=0.0002, beta_1=0.5), loss='binary_crossentropy')\n",
        "\n",
        "# Compile GAN\n",
        "gan.compile(optimizer=Adam(learning_rate=0.0002, beta_1=0.5), loss='binary_crossentropy')\n",
        "\n",
        "# Training the GAN\n",
        "epochs = 5000\n",
        "batch_size = 32\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    idx = np.random.randint(0, df_normalized.shape[0], batch_size)\n",
        "    real_data = df_normalized.iloc[idx]\n",
        "\n",
        "    noise = np.random.normal(0, 1, size=[batch_size, 9])\n",
        "    generated_data = generator.predict(noise)\n",
        "\n",
        "    X = np.concatenate([real_data, generated_data])\n",
        "    y_dis = np.zeros(2 * batch_size)\n",
        "    y_dis[:batch_size] = 0.9\n",
        "\n",
        "    d_loss = discriminator.train_on_batch(X, y_dis)\n",
        "\n",
        "    noise = np.random.normal(0, 1, size=[batch_size, 9])\n",
        "    y_gen = np.ones(batch_size)\n",
        "\n",
        "    g_loss = gan.train_on_batch(noise, y_gen)\n",
        "\n",
        "    if epoch % 100 == 0:\n",
        "        print(f\"Epoch {epoch} | Discriminator Loss: {d_loss} | Generator Loss: {g_loss}\")\n",
        "\n",
        "# Generate synthetic normal data\n",
        "noise = np.random.normal(0, 1, size=[df_normalized.shape[0], 9])\n",
        "synthetic_normal_data = generator.predict(noise)\n",
        "\n",
        "# Calculate BCE loss between actual and synthetic normal data\n",
        "bce_loss = np.mean(np.abs(df_normalized - synthetic_normal_data), axis=1)\n",
        "\n",
        "# Adjust anomaly threshold based on your experimentation\n",
        "anomaly_threshold = 0.7  # You can try different values\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bw8S_s6RX-j1"
      },
      "outputs": [],
      "source": [
        "\n",
        "anomalies = df.reset_index()[bce_loss > anomaly_threshold]\n",
        "\n",
        "# Get timestamps of anomalies\n",
        "anomaly_timestamps = anomalies['Timestamp']\n",
        "\n",
        "\n",
        "print(\"Anomaly Timestamps:\")\n",
        "print(anomaly_timestamps)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}